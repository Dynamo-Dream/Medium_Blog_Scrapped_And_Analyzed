{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9c0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcfc3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e8922",
   "metadata": {},
   "source": [
    "\n",
    "Description:\n",
    "    This script utilizes Selenium WebDriver to automate the task of scraping content from a Medium author's profile page.\n",
    "\n",
    "Steps:\n",
    "1. Initialize WebDriver:\n",
    "    - Set up the ChromeDriver service using the provided path to the ChromeDriver executable.\n",
    "    - Initialize the Chrome WebDriver, passing the service.\n",
    "\n",
    "2. Navigate to the Author's Profile Page:\n",
    "    - Open the author's Medium profile page specified by the URL.\n",
    "\n",
    "3. Load Dynamic Content:\n",
    "    - Scroll down the page to load more content dynamically until reaching the bottom.\n",
    "    - Get the initial height of the page and continuously scroll down while waiting for more content to load.\n",
    "    - Break the loop if no more content is loaded, indicated by no increase in the page height.\n",
    "\n",
    "4. Extract HTML Content:\n",
    "    - After loading all content, switch to the newly opened window (if any).\n",
    "    - Get the HTML content of the page using JavaScript execution.\n",
    "\n",
    "5. Close WebDriver:\n",
    "    - Quit the WebDriver to release resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0166dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_path = \"chromedriver.exe\" \n",
    "service = Service(executable_path=chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "author_profile_url = \"https://williamkoehrsen.medium.com/\" \n",
    "driver.get(author_profile_url)\n",
    "main_window_handle = driver.current_window_handle\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    time.sleep(10)\n",
    "    \n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    \n",
    "    last_height = new_height\n",
    "for window_handle in driver.window_handles:\n",
    "    if window_handle != main_window_handle:\n",
    "        driver.switch_to.window(window_handle)\n",
    "        break\n",
    "\n",
    "res = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914af07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451bb392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Will Koehrsen'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = soup.title.string\n",
    "author = author.split(\" – \")[0]\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c53343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Soup to extract Links and Tags Related To Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d358c82",
   "metadata": {},
   "source": [
    "## Extract Tags of Blogs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f5a5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848a330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_element = soup.find_all(\"div\", class_=re.compile(\"nf dl fk ng nh ni nj be b do z\"))\n",
    "tags_temp = []\n",
    "for ind,tag in enumerate(tags_element):\n",
    "    if(ind%2 == 0):\n",
    "        tags_temp.append(tag.get_text(strip = True))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e43c1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science', 'Data Science', 'Reading', 'Reading', 'Productivity']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_temp[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354ffc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67c4f0",
   "metadata": {},
   "source": [
    "## Extract Links of Blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c146d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_links = soup.find_all('div',class_='ab ks')\n",
    "href_links=[]\n",
    "for index,div in enumerate(filtered_links):\n",
    "    if index%2 != 0:\n",
    "        continue\n",
    "    link = div.find('a')\n",
    "    if link:\n",
    "        href = link.get('href')\n",
    "        href = \"https://williamkoehrsen.medium.com\"+href\n",
    "        href = href.split('?')[0]\n",
    "        href_links.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5441ead1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://williamkoehrsen.medium.com/drivendata-interview-3ab44269ef84',\n",
       " 'https://williamkoehrsen.medium.com/a-data-science-conversation-9ca398573d2f']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href_links[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56c09895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(href_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19473db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # TO VIsualize the Scraping Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96368fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "428c1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(cssSelector, webDriverWait, max_retry=3):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This function is designed to scrape text content from a web page using Selenium WebDriver.\n",
    "        \n",
    "    Parameters:\n",
    "        cssSelector (str): A CSS selector used to locate the desired element on the web page.\n",
    "        webDriverWait (WebDriverWait): An instance of WebDriverWait configured with the desired timeout.\n",
    "        max_retry (int, optional): The maximum number of retry attempts in case of StaleElementReferenceException.\n",
    "                                   Defaults to 3.\n",
    "                                   \n",
    "    Returns:\n",
    "        str: The text content of the located element, stripped of leading and trailing whitespaces.\n",
    "             If the element is not found or if it has no text content, it returns \"0\".\n",
    "    \"\"\"\n",
    "    retry_count = 0\n",
    "    element = None\n",
    "    while retry_count < max_retry:\n",
    "        try:\n",
    "            element = webDriverWait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, cssSelector)))\n",
    "            return element.text.strip() if element.text.strip() else \"0\"\n",
    "        \n",
    "        except StaleElementReferenceException:\n",
    "            print(\"Stale Element Exception occurred. Retrying...\")\n",
    "            retry_count += 1\n",
    "        except NoSuchElementException:\n",
    "            return \"0\"\n",
    "    return \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f732c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_paragraph(cssSelector, wait,max_retry=3):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This function is designed to scrape text content from multiple paragraphs on a web page using Selenium WebDriver.\n",
    "        \n",
    "    Parameters:\n",
    "        cssSelector (str): A CSS selector used to locate the desired paragraph elements on the web page.\n",
    "        wait (WebDriverWait): An instance of WebDriverWait configured with the desired timeout.\n",
    "        max_retry (int, optional): The maximum number of retry attempts in case of StaleElementReferenceException.\n",
    "                                   Defaults to 3.\n",
    "                                   \n",
    "    Returns:\n",
    "        str: The concatenated text content of all located paragraph elements, separated by spaces.\n",
    "             If no paragraph elements are found or if they have no text content, it returns \"0\".\n",
    "    \"\"\"\n",
    "    retry_count = 0\n",
    "    paragraph = None\n",
    "    try:\n",
    "        all_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, cssSelector)))\n",
    "        paragraphs = [element.text for element in all_elements]\n",
    "        return \" \".join(paragraphs) if paragraphs else \"0\"\n",
    "    except StaleElementReferenceException:\n",
    "        print(\"Stale Element Exception occurred. Retrying...\")\n",
    "        return \"0\"\n",
    "    return \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "187300cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d363e2faa34433818d4c46f10e1ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Links:   0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scraping the Websites from the links scraped above\n",
    "upvotes = []\n",
    "comment_count = []\n",
    "title = []\n",
    "read_time = []\n",
    "publish_date = []\n",
    "paragraphs = []\n",
    "author = []\n",
    "links = []\n",
    "tags = []\n",
    "for ind, link in tqdm(enumerate(href_links), desc=\"Processing Links\", total=len(href_links)):\n",
    "    chromedriver_path = \"chromedriver.exe\" \n",
    "    service = Service(executable_path=chromedriver_path)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    \n",
    "    try:\n",
    "        driver.get(link)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        \n",
    "        title_element = scrape_data('h1[data-testid*=\"storyTitle\"]', wait, 3)\n",
    "        author_element = scrape_data('a[data-testid*=\"authorName\"]', wait, 3)\n",
    "        upvotes_element = scrape_data('div.pw-multi-vote-count button', wait, 3)\n",
    "        comment_count_element = scrape_data('span[class*=\"pw-responses-count\"]', wait, 3)\n",
    "        read_time_element = scrape_data('span[data-testid*=\"storyReadTime\"]', wait, 3)\n",
    "        publish_date_element = scrape_data('span[data-testid*=\"storyPublishDate\"]', wait, 3)\n",
    "        paragraph_element = scrape_paragraph('p.pw-post-body-paragraph', wait, 3)\n",
    "        \n",
    "        title.append(title_element)\n",
    "        author.append(author_element)\n",
    "        upvotes.append(upvotes_element)\n",
    "        comment_count.append(comment_count_element)\n",
    "        read_time.append(read_time_element)\n",
    "        publish_date.append(publish_date_element)\n",
    "        paragraphs.append(paragraph_element)\n",
    "        links.append(link)\n",
    "        tags.append(tags_temp[ind])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00dd9116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f09c107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(title), len(author), len(upvotes), len(comment_count),\n",
    "                 len(publish_date), len(read_time), len(paragraphs), len(links), len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6066d1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length # Getting Max Length TO Pad the Columns With Shorter Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "971ab578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the shorter lists with a placeholder value (e.g., '')\n",
    "title += [''] * (max_length - len(title))\n",
    "author += [''] * (max_length - len(author))\n",
    "upvotes += [0] * (max_length - len(upvotes))  \n",
    "comment_count += [0] * (max_length - len(comment_count))  \n",
    "publish_date += [''] * (max_length - len(publish_date))\n",
    "read_time += [0] * (max_length - len(read_time))  \n",
    "paragraphs += [''] * (max_length - len(paragraphs))\n",
    "links += [''] * (max_length - len(links))\n",
    "tags += [''] * (max_length - len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20378838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"title\":title,\"Author\":author,\"Upvote\":upvotes,\"CommentCount\":comment_count,\"Publish Date\":publish_date, \"Read Time\":read_time, \"Paragraph\":paragraphs,\"Links\":links,\"Tag\":tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5e826c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Upvote</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>Publish Date</th>\n",
       "      <th>Read Time</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Links</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DrivenData Interview</td>\n",
       "      <td>Will Koehrsen</td>\n",
       "      <td>544</td>\n",
       "      <td>2</td>\n",
       "      <td>Dec 14, 2020</td>\n",
       "      <td>13 min read</td>\n",
       "      <td>In October 2020, I was interviewed by DrivenDa...</td>\n",
       "      <td>https://williamkoehrsen.medium.com/drivendata-...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Data Science Conversation</td>\n",
       "      <td>Will Koehrsen</td>\n",
       "      <td>411</td>\n",
       "      <td>43</td>\n",
       "      <td>Mar 10, 2020</td>\n",
       "      <td>3 min read</td>\n",
       "      <td>Talking is a lot like writing in that it force...</td>\n",
       "      <td>https://williamkoehrsen.medium.com/a-data-scie...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 Lessons from 55,000 pages of books</td>\n",
       "      <td>Will Koehrsen</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>10</td>\n",
       "      <td>Jan 2, 2020</td>\n",
       "      <td>14 min read</td>\n",
       "      <td>Reading 136 books in a year does not get you t...</td>\n",
       "      <td>https://williamkoehrsen.medium.com/12-lessons-...</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Books of 2019</td>\n",
       "      <td>Will Koehrsen</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan 1, 2020</td>\n",
       "      <td>58 min read</td>\n",
       "      <td>Before we get started: reading books does not ...</td>\n",
       "      <td>https://williamkoehrsen.medium.com/books-of-20...</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Just Do It” Won’t Get You to Your Goals</td>\n",
       "      <td>Will Koehrsen</td>\n",
       "      <td>398</td>\n",
       "      <td>2</td>\n",
       "      <td>Dec 27, 2019</td>\n",
       "      <td>12 min read</td>\n",
       "      <td>Rule number one for achieving goals: don’t tak...</td>\n",
       "      <td>https://williamkoehrsen.medium.com/just-do-it-...</td>\n",
       "      <td>Productivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>The Triumph of Peace</td>\n",
       "      <td>Will Koehrsen</td>\n",
       "      <td>7.9K</td>\n",
       "      <td>43</td>\n",
       "      <td>Jul 5, 2017</td>\n",
       "      <td>14 min read</td>\n",
       "      <td>A review of The Better Angels of Our Nature: W...</td>\n",
       "      <td>https://williamkoehrsen.medium.com/the-triumph...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Home of the Scared</td>\n",
       "      <td>Will Koehrsen</td>\n",
       "      <td>7.9K</td>\n",
       "      <td>43</td>\n",
       "      <td>Jul 1, 2017</td>\n",
       "      <td>9 min read</td>\n",
       "      <td>A review of A Culture of Fear: Why Americans a...</td>\n",
       "      <td>https://williamkoehrsen.medium.com/home-of-the...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Capstone Project: Mercedes-Benz Greener Manufa...</td>\n",
       "      <td>Will Koehrsen</td>\n",
       "      <td>120</td>\n",
       "      <td>43</td>\n",
       "      <td>Jun 30, 2017</td>\n",
       "      <td>42 min read</td>\n",
       "      <td>Author’s Note: This is the report I completed ...</td>\n",
       "      <td>https://williamkoehrsen.medium.com/capstone-pr...</td>\n",
       "      <td>Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>The Vanquishing of War, Plague and Famine</td>\n",
       "      <td>Will Koehrsen</td>\n",
       "      <td>70</td>\n",
       "      <td>43</td>\n",
       "      <td>Jun 18, 2017</td>\n",
       "      <td>14 min read</td>\n",
       "      <td>Part 1 of the Optimist’s Guide to the 21st Cen...</td>\n",
       "      <td>https://williamkoehrsen.medium.com/the-vanquis...</td>\n",
       "      <td>Climate Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Screw the Environment, but Consider Your Wallet</td>\n",
       "      <td>Will Koehrsen</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>Jun 11, 2017</td>\n",
       "      <td>7 min read</td>\n",
       "      <td>When the Health of the Environment and the Hea...</td>\n",
       "      <td>https://williamkoehrsen.medium.com/screw-the-e...</td>\n",
       "      <td>Climate Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title         Author Upvote  \\\n",
       "0                                 DrivenData Interview  Will Koehrsen    544   \n",
       "1                          A Data Science Conversation  Will Koehrsen    411   \n",
       "2                12 Lessons from 55,000 pages of books  Will Koehrsen   1.4K   \n",
       "3                                        Books of 2019  Will Koehrsen    464   \n",
       "4             “Just Do It” Won’t Get You to Your Goals  Will Koehrsen    398   \n",
       "..                                                 ...            ...    ...   \n",
       "150                               The Triumph of Peace  Will Koehrsen   7.9K   \n",
       "151                                 Home of the Scared  Will Koehrsen   7.9K   \n",
       "152  Capstone Project: Mercedes-Benz Greener Manufa...  Will Koehrsen    120   \n",
       "153          The Vanquishing of War, Plague and Famine  Will Koehrsen     70   \n",
       "154    Screw the Environment, but Consider Your Wallet  Will Koehrsen      7   \n",
       "\n",
       "    CommentCount  Publish Date    Read Time  \\\n",
       "0              2  Dec 14, 2020  13 min read   \n",
       "1             43  Mar 10, 2020   3 min read   \n",
       "2             10   Jan 2, 2020  14 min read   \n",
       "3              1   Jan 1, 2020  58 min read   \n",
       "4              2  Dec 27, 2019  12 min read   \n",
       "..           ...           ...          ...   \n",
       "150           43   Jul 5, 2017  14 min read   \n",
       "151           43   Jul 1, 2017   9 min read   \n",
       "152           43  Jun 30, 2017  42 min read   \n",
       "153           43  Jun 18, 2017  14 min read   \n",
       "154           43  Jun 11, 2017   7 min read   \n",
       "\n",
       "                                             Paragraph  \\\n",
       "0    In October 2020, I was interviewed by DrivenDa...   \n",
       "1    Talking is a lot like writing in that it force...   \n",
       "2    Reading 136 books in a year does not get you t...   \n",
       "3    Before we get started: reading books does not ...   \n",
       "4    Rule number one for achieving goals: don’t tak...   \n",
       "..                                                 ...   \n",
       "150  A review of The Better Angels of Our Nature: W...   \n",
       "151  A review of A Culture of Fear: Why Americans a...   \n",
       "152  Author’s Note: This is the report I completed ...   \n",
       "153  Part 1 of the Optimist’s Guide to the 21st Cen...   \n",
       "154  When the Health of the Environment and the Hea...   \n",
       "\n",
       "                                                 Links               Tag  \n",
       "0    https://williamkoehrsen.medium.com/drivendata-...      Data Science  \n",
       "1    https://williamkoehrsen.medium.com/a-data-scie...      Data Science  \n",
       "2    https://williamkoehrsen.medium.com/12-lessons-...           Reading  \n",
       "3    https://williamkoehrsen.medium.com/books-of-20...           Reading  \n",
       "4    https://williamkoehrsen.medium.com/just-do-it-...      Productivity  \n",
       "..                                                 ...               ...  \n",
       "150  https://williamkoehrsen.medium.com/the-triumph...             Books  \n",
       "151  https://williamkoehrsen.medium.com/home-of-the...          Politics  \n",
       "152  https://williamkoehrsen.medium.com/capstone-pr...  Machine Learning  \n",
       "153  https://williamkoehrsen.medium.com/the-vanquis...    Climate Change  \n",
       "154  https://williamkoehrsen.medium.com/screw-the-e...    Climate Change  \n",
       "\n",
       "[155 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b56bc0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('MediumBlogScrapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaacc22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc960d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6b1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
